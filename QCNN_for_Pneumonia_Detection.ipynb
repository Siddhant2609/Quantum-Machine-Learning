{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLeF5Nmdef0V"
      },
      "source": [
        "# Quantum Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D3xaWBHOIVg"
      },
      "source": [
        "This tutorial implements a simplified <a href=\"https://www.nature.com/articles/s41567-019-0648-8\" class=\"external\">Quantum Convolutional Neural Network</a> (QCNN), a proposed quantum analogue to a classical convolutional neural network that is also *translationally invariant*.\n",
        "\n",
        "This example demonstrates how to detect certain properties of a quantum data source, such as a quantum sensor or a complex simulation from a device. The quantum data source being a <a href=\"https://arxiv.org/pdf/quant-ph/0504097.pdf\" class=\"external\">cluster state</a> that may or may not have an excitationâ€”what the QCNN will learn to detect (The dataset used in the paper was SPT phase classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnjolLuz8o5C"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aquwcz-0aHqz",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ZuLN_N8yhT"
      },
      "source": [
        "Install TensorFlow Quantum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Pl5PW-ACO9J",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-quantum==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ql5PW-ACO0J",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL_LvHXzPNjW"
      },
      "source": [
        "Now import TensorFlow and the module dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QytLEAtoejW5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6331ZSsQGY3"
      },
      "source": [
        "## 1. Build a QCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg85u3G--CGq"
      },
      "source": [
        "### 1.1 Assemble circuits in a TensorFlow graph\n",
        "\n",
        "TensorFlow Quantum (TFQ) provides layer classes designed for in-graph circuit construction. One example is the `tfq.layers.AddCircuit` layer that inherits from `tf.keras.Layer`. This layer can either prepend or append to the input batch of circuits, as shown in the following figure.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/qcnn_1.png?raw=1\" width=\"700\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Data from Kaggle"
      ],
      "metadata": {
        "id": "P-mowA9zokaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n"
      ],
      "metadata": {
        "id": "kIn2ikkwJ6kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "njICFLHOJ6Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "O3oU23x5KF1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "QXfyVIvAJ6P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "  \n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\")"
      ],
      "metadata": {
        "id": "EBsfkbs1J6Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import system libs\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "import itertools\n",
        "\n",
        "# import data handling tools\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# import Deep learning Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('modules loaded')"
      ],
      "metadata": {
        "id": "mnCPuH8cJ5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data paths with labels\n",
        "data_dir = '/content/chest-xray-pneumonia/chest_xray/train'\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(data_dir)\n",
        "for fold in folds:\n",
        "    foldpath = os.path.join(data_dir, fold)\n",
        "    filelist = os.listdir(foldpath)\n",
        "    for file in filelist:\n",
        "        fpath = os.path.join(foldpath, file)\n",
        "        filepaths.append(fpath)\n",
        "        labels.append(fold)\n",
        "\n",
        "# Concatenate data paths with labels into one dataframe\n",
        "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
        "Lseries = pd.Series(labels, name='labels')\n",
        "df = pd.concat([Fseries, Lseries], axis= 1)"
      ],
      "metadata": {
        "id": "CWbhs0rCJ5mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataframe\n",
        "train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)\n",
        "\n",
        "# valid and test dataframe\n",
        "valid_df, test_df = train_test_split(dummy_df,  train_size= 0.6, shuffle= True, random_state= 123)"
      ],
      "metadata": {
        "id": "xqa-IEzBJ5ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crobed image size\n",
        "batch_size = 16\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "# Recommended : use custom function for test data batch size, else we can use normal batch size.\n",
        "ts_length = len(test_df)\n",
        "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "\n",
        "# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n",
        "def scalar(img):\n",
        "    return img\n",
        "\n",
        "tr_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "# Note: we will use custom test_batch_size, and make shuffle= false\n",
        "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)"
      ],
      "metadata": {
        "id": "WIMyDeF7J5V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen.class_indices"
      ],
      "metadata": {
        "id": "kOkWI5zbJ5QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
        "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
        "images, labels = next(train_gen)      # get a batch size samples from the generator\n",
        "\n",
        "plt.figure(figsize= (20, 20))\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    image = images[i] / 255       # scales data to range (0 - 255)\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])  # get image index\n",
        "    class_name = classes[index]   # get class of image\n",
        "    plt.title(class_name, color= 'blue', fontsize= 12)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-hoIoaAoJ5J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "ZBJBFUcdJ5C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#     return np.array(data)\n",
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 150\n",
        "def get_training_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "Df38jxhQJ4eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = get_training_data('/content/chest-xray-pneumonia/chest_xray/train')\n",
        "val = get_training_data('/content/chest-xray-pneumonia/chest_xray/val')\n",
        "test = get_training_data('/content/chest-xray-pneumonia/chest_xray/val')"
      ],
      "metadata": {
        "id": "D_Y84FKRJ4Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(train[0][0], cmap = 'gray')\n",
        "plt.title(labels[train[0][1]])\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(train[-1][0], cmap = 'gray')\n",
        "plt.title(labels[train[-1][1]])"
      ],
      "metadata": {
        "id": "ZPVPE-OEJ3_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "x_test =[]\n",
        "y_test = []\n",
        "\n",
        "for feature, label in train:\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "    \n",
        "\n",
        "for feature, label in val:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)\n",
        "    \n",
        "for feature, label in train:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "    "
      ],
      "metadata": {
        "id": "c0dQ6H_EK6bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)/255\n",
        "x_val = np.array(x_val)/255\n",
        "x_test = np.array(x_test)/255"
      ],
      "metadata": {
        "id": "dQAopBg8K6O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1,img_size,img_size,1)\n",
        "y_train = np.array(y_train)\n",
        "y_train\n",
        "x_val = x_val.reshape(-1,img_size,img_size,1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "x_test = x_test.reshape(-1,img_size,img_size,1)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "mqerXkLaK6AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ],
      "metadata": {
        "id": "IYQf7eA2K5yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= tf.cast(x_train, tf.float32)\n",
        "x_test=tf.cast(x_test, tf.float32)\n",
        "\n",
        "x_train = tf.image.resize(x_train[:], (10,10)).numpy()\n",
        "x_test = tf.image.resize(x_test[:], (10,10)).numpy()\n",
        "\n",
        "y_train = y_train[:]\n",
        "y_test = y_test[:]"
      ],
      "metadata": {
        "id": "-NQsTPQOK5op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0])\n",
        "fig = plt.figure()\n",
        "plt.imshow(x_train[0, :, :, 0], cmap='gray_r')\n",
        "plt.colorbar()\n",
        "fig.savefig('sample', dpi=300)"
      ],
      "metadata": {
        "id": "VlLlh2I5K5is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = np.shape(x_train)[1]\n",
        "height = np.shape(x_train)[2]\n",
        "\n",
        "fc_model = models.Sequential()\n",
        "\n",
        "fc_model.add(layers.Flatten(input_shape=(width,height,1)))\n",
        "fc_model.add(layers.Dense(32, activation='relu'))\n",
        "fc_model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "oovviqRTK5ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fc_history = fc_model.fit(x_train, y_train, steps_per_epoch=500,\n",
        "                        validation_data=(x_test, y_test), \n",
        "                        epochs=50, batch_size=5)"
      ],
      "metadata": {
        "id": "Q5pHsXn_K5U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = np.shape(x_train)[1]\n",
        "height = np.shape(x_train)[2]\n",
        "\n",
        "cnn_model = models.Sequential()\n",
        "\n",
        "cnn_model.add(layers.Conv2D(8, (2, 2), activation='relu', input_shape=(width, height, 1)))\n",
        "#model.add(layers.MaxPooling2D((2, 2)))\n",
        "#model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
        "\n",
        "cnn_model.add(layers.Flatten())\n",
        "cnn_model.add(layers.Dense(32, activation='relu'))\n",
        "cnn_model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "O-R52mhxK5Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "A-cflSYbK5Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "cnn_history = cnn_model.fit(x_train, y_train, steps_per_epoch=500,\n",
        "                        validation_data=(x_test, y_test), \n",
        "                        epochs=50, batch_size=5)"
      ],
      "metadata": {
        "id": "I_qwzSTEK4vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = cnn_model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "tB5PVdlTK4hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QConv(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_size, depth, activation=None, name=None, kernel_regularizer=None, **kwangs):\n",
        "        super(QConv, self).__init__(name=name, **kwangs)\n",
        "        self.filter_size = filter_size\n",
        "        self.depth = depth\n",
        "        self.learning_params = []\n",
        "        self.QCNN_layer_gen()\n",
        "        # self.circuit_tensor = tfq.convert_to_tensor([self.circuit])\n",
        "        self.activation = tf.keras.layers.Activation(activation)\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "\n",
        "    def _next_qubit_set(self, original_size, next_size, qubits):\n",
        "        step = original_size // next_size\n",
        "        qubit_list = []\n",
        "        for i in range(0, original_size, step):\n",
        "            for j in range(0, original_size, step):\n",
        "                qubit_list.append(qubits[original_size*i + j])\n",
        "        return qubit_list\n",
        "\n",
        "    def _get_new_param(self):\n",
        "        \"\"\"\n",
        "        return new learnable parameter\n",
        "        all returned parameter saved in self.learning_params\n",
        "        \"\"\"\n",
        "        new_param = sympy.symbols(\"p\"+str(len(self.learning_params)))\n",
        "        self.learning_params.append(new_param)\n",
        "        return new_param\n",
        "    \n",
        "    def _QConv(self, step, target, qubits):\n",
        "        \"\"\"\n",
        "        apply learnable gates each quantum convolutional layer level\n",
        "        \"\"\"\n",
        "        yield cirq.CZPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
        "        yield cirq.CXPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
        "        \n",
        "    def QCNN_layer_gen(self):\n",
        "        \"\"\"\n",
        "        make quantum convolutional layer in QConv layer\n",
        "        \"\"\"\n",
        "        pixels = self.filter_size**2\n",
        "        # filter size: 2^n only for this version!\n",
        "        if np.log2(pixels) % 1 != 0:\n",
        "            raise NotImplementedError(\"filter size: 2^n only available\")\n",
        "        cirq_qubits = cirq.GridQubit.rect(self.filter_size, self.filter_size)\n",
        "        # mapping input data to circuit\n",
        "        input_circuit = cirq.Circuit()\n",
        "        input_params = [sympy.symbols('a%d' %i) for i in range(pixels)]\n",
        "        for i, qubit in enumerate(cirq_qubits):\n",
        "            input_circuit.append(cirq.rx(np.pi*input_params[i])(qubit))\n",
        "        # apply learnable gate set to QCNN circuit\n",
        "        QCNN_circuit = cirq.Circuit()\n",
        "        step_size = [2**i for i in range(np.log2(pixels).astype(np.int32))]\n",
        "        for step in step_size:\n",
        "            for target in range(0, pixels, 2*step):\n",
        "                QCNN_circuit.append(self._QConv(step, target, cirq_qubits))\n",
        "        # merge the circuits\n",
        "        full_circuit = cirq.Circuit()\n",
        "        full_circuit.append(input_circuit)\n",
        "        full_circuit.append(QCNN_circuit)\n",
        "        self.circuit = full_circuit # save circuit to the QCNN layer obj.\n",
        "        self.params = input_params + self.learning_params\n",
        "        self.op = cirq.Z(cirq_qubits[0])\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.width = input_shape[1]\n",
        "        self.height = input_shape[2]\n",
        "        self.channel = input_shape[3]\n",
        "        self.num_x = self.width - self.filter_size + 1\n",
        "        self.num_y = self.height - self.filter_size + 1\n",
        "        \n",
        "        self.kernel = self.add_weight(name=\"kenel\", \n",
        "                                      shape=[self.depth, \n",
        "                                             self.channel, \n",
        "                                             len(self.learning_params)],\n",
        "                                     initializer=tf.keras.initializers.glorot_normal(),\n",
        "                                     regularizer=self.kernel_regularizer)\n",
        "        self.circuit_tensor = tfq.convert_to_tensor([self.circuit] * self.num_x * self.num_y * self.channel)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # input shape: [N, width, height, channel]\n",
        "        # slide and collect data\n",
        "        stack_set = None\n",
        "        for i in range(self.num_x):\n",
        "            for j in range(self.num_y):\n",
        "                slice_part = tf.slice(inputs, [0, i, j, 0], [-1, self.filter_size, self.filter_size, -1])\n",
        "                slice_part = tf.reshape(slice_part, shape=[-1, 1, self.filter_size, self.filter_size, self.channel])\n",
        "                if stack_set == None:\n",
        "                    stack_set = slice_part\n",
        "                else:\n",
        "                    stack_set = tf.concat([stack_set, slice_part], 1)  \n",
        "        # -> shape: [N, num_x*num_y, filter_size, filter_size, channel]\n",
        "        stack_set = tf.transpose(stack_set, perm=[0, 1, 4, 2, 3])\n",
        "        # -> shape: [N, num_x*num_y, channel, filter_size, fiter_size]\n",
        "        stack_set = tf.reshape(stack_set, shape=[-1, self.filter_size**2])\n",
        "        # -> shape: [N*num_x*num_y*channel, filter_size^2]\n",
        "        \n",
        "        # total input citcuits: N * num_x * num_y * channel\n",
        "        circuit_inputs = tf.tile([self.circuit_tensor], [tf.shape(inputs)[0], 1])\n",
        "        circuit_inputs = tf.reshape(circuit_inputs, shape=[-1])\n",
        "        tf.fill([tf.shape(inputs)[0]*self.num_x*self.num_y, 1], 1)\n",
        "        outputs = []\n",
        "        for i in range(self.depth):\n",
        "            controller = tf.tile(self.kernel[i], [tf.shape(inputs)[0]*self.num_x*self.num_y, 1])\n",
        "            outputs.append(self.single_depth_QCNN(stack_set, controller, circuit_inputs))\n",
        "            # shape: [N, num_x, num_y] \n",
        "            \n",
        "        output_tensor = tf.stack(outputs, axis=3)\n",
        "        output_tensor = tf.math.acos(tf.clip_by_value(output_tensor, -1+1e-5, 1-1e-5)) / np.pi\n",
        "        # output_tensor = tf.clip_by_value(tf.math.acos(output_tensor)/np.pi, -1, 1)\n",
        "        return self.activation(output_tensor)\n",
        "          \n",
        "    def single_depth_QCNN(self, input_data, controller, circuit_inputs):\n",
        "        \"\"\"\n",
        "        make QCNN for 1 channel only\n",
        "        \"\"\"\n",
        "        # input shape: [N*num_x*num_y*channel, filter_size^2]\n",
        "        # controller shape: [N*num_x*num_y*channel, len(learning_params)]\n",
        "        input_data = tf.concat([input_data, controller], 1)\n",
        "        # input_data shape: [N*num_x*num_y*channel, len(learning_params)]\n",
        "        QCNN_output = tfq.layers.Expectation()(circuit_inputs, \n",
        "                                               symbol_names=self.params,\n",
        "                                               symbol_values=input_data,\n",
        "                                               operators=self.op)\n",
        "        # QCNN_output shape: [N*num_x*num_y*channel]\n",
        "        QCNN_output = tf.reshape(QCNN_output, shape=[-1, self.num_x, self.num_y, self.channel])\n",
        "        return tf.math.reduce_sum(QCNN_output, 3)\n",
        "        "
      ],
      "metadata": {
        "id": "89uRP-MCK4TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = np.shape(x_train)[1]\n",
        "height = np.shape(x_train)[2]\n",
        "\n",
        "qcnn_model = models.Sequential()\n",
        "\n",
        "\n",
        "qcnn_model.add(QConv(filter_size=2, depth=8, activation='relu', \n",
        "                     name='qconv1', input_shape=(width, height, 1)))\n",
        "#model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
        "qcnn_model.add(layers.Flatten())\n",
        "qcnn_model.add(layers.Dense(32, activation='relu'))\n",
        "qcnn_model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "Fs1xVqnPK4Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qcnn_model.summary()"
      ],
      "metadata": {
        "id": "P03vJNLAK32W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVGCircuit(QConv(filter_size=2, depth=0, activation='relu').circuit)"
      ],
      "metadata": {
        "id": "XdfshibbL1SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "import graphviz\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(qcnn_model, to_file='model_shapes.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "j0j1SGyEL1HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qcnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "qcnn_history = qcnn_model.fit(x_train, y_train, steps_per_epoch=200,\n",
        "                        validation_data=(x_test, y_test), \n",
        "                        epochs=20, batch_size=5)"
      ],
      "metadata": {
        "id": "HQd1JY7jL08x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = qcnn_model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "HrDzQzFhL0vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(8):\n",
        "    fig = plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(qcnn_model.get_layer('qconv1')(x_train[0:1,:,:,:])[0,:,:,i], cmap='gray_r')\n",
        "    fig.savefig('qcnn_%d'%i, dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "IniGGxnpL0TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(fc_loss, cnn_loss, qcnn_loss):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(np.arange(len(fc_loss)) + 1, fc_loss, \"go-\", label=\"fully-connected\")\n",
        "    plt.plot(np.arange(len(cnn_loss)) + 1, cnn_loss, \"rs-\", label=\"CNN\")\n",
        "    plt.plot(np.arange(len(qcnn_loss)) + 1, qcnn_loss, \"b^-\", label=\"QCNN\")\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.axis([1, 50, 0, 1])\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Test set loss\")\n",
        "    plt.grid(True)\n",
        "    fig.savefig('loss.png', dpi=300)\n",
        "    \n",
        "def plot_loss_curves_small(fc_loss, cnn_loss, qcnn_loss):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(np.arange(len(fc_loss))[::2] + 1, fc_loss[::2], \"go-\", label=\"fully-connected\")\n",
        "    plt.plot(np.arange(len(cnn_loss))[::2] + 1, cnn_loss[::2], \"rs-\", label=\"CNN\")\n",
        "    plt.plot(np.arange(len(qcnn_loss))[::2] + 1, qcnn_loss[::2], \"b^-\", label=\"QCNN\")\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.axis([1, 50, 0, 1])\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Test set loss\")\n",
        "    plt.grid(True)\n",
        "    fig.savefig('loss_small.png', dpi=300)"
      ],
      "metadata": {
        "id": "rundo6puL0C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(fc_history.history['val_loss'], cnn_history.history['val_loss'], qcnn_history.history['val_loss'])\n"
      ],
      "metadata": {
        "id": "Q224JTpyLz2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves_small(fc_history.history['val_loss'], cnn_history.history['val_loss'], qcnn_history.history['val_loss'])\n"
      ],
      "metadata": {
        "id": "Xy1dxpJqK3gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_acc_curves(fc_acc, cnn_acc, qcnn_acc):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(np.arange(len(fc_acc)) + 1, fc_acc, \"go-\", label=\"fully-connected\")\n",
        "    plt.plot(np.arange(len(cnn_acc)) + 1, cnn_acc, \"rs-\", label=\"CNN\")\n",
        "    plt.plot(np.arange(len(qcnn_acc)) + 1, qcnn_acc, \"b^-\", label=\"QCNN\")\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.grid()\n",
        "    plt.axis([1, 50, 0.8, 1])\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Test set accuracy\")\n",
        "    fig.savefig('accuracy.png', dpi=300)\n",
        "    \n",
        "def plot_acc_curves_small(fc_acc, cnn_acc, qcnn_acc):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(np.arange(len(fc_acc))[::2] + 1, fc_acc[::2], \"go-\", label=\"fully-connected\")\n",
        "    plt.plot(np.arange(len(cnn_acc))[::2] + 1, cnn_acc[::2], \"rs-\", label=\"CNN\")\n",
        "    plt.plot(np.arange(len(qcnn_acc))[::2] + 1, qcnn_acc[::2], \"b^-\", label=\"QCNN\")\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.grid()\n",
        "    plt.axis([1, 50, 0.8, 1])\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Test set accuracy\")\n",
        "    fig.savefig('accuracy_small.png', dpi=300)"
      ],
      "metadata": {
        "id": "PsCr8dH-K2R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_curves(fc_history.history['val_accuracy'], cnn_history.history['val_accuracy'], qcnn_history.history['val_accuracy'])\n"
      ],
      "metadata": {
        "id": "-nWbGoXpMK4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_curves_small(fc_history.history['val_accuracy'], cnn_history.history['val_accuracy'], qcnn_history.history['val_accuracy'])\n"
      ],
      "metadata": {
        "id": "C5W5acw6MKxP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}